\hypertarget{cuda_model_matrix_8h}{}\doxysection{Markopy/\+Cuda\+Markov\+API/src/cuda\+Model\+Matrix.h File Reference}
\label{cuda_model_matrix_8h}\index{Markopy/CudaMarkovAPI/src/cudaModelMatrix.h@{Markopy/CudaMarkovAPI/src/cudaModelMatrix.h}}


CUDA accelerated extension of \mbox{\hyperlink{class_markov_1_1_a_p_i_1_1_model_matrix}{Markov\+::\+API\+::\+Model\+Matrix}}.  


{\ttfamily \#include \char`\"{}Markov\+API/src/model\+Matrix.\+h\char`\"{}}\newline
{\ttfamily \#include \char`\"{}cuda\+Device\+Controller.\+h\char`\"{}}\newline
Include dependency graph for cuda\+Model\+Matrix.\+h\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{cuda_model_matrix_8h__incl}
\end{center}
\end{figure}
This graph shows which files directly or indirectly include this file\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{cuda_model_matrix_8h__dep__incl}
\end{center}
\end{figure}
\doxysubsection*{Classes}
\begin{DoxyCompactItemize}
\item 
class \mbox{\hyperlink{class_markov_1_1_a_p_i_1_1_c_u_d_a_1_1_c_u_d_a_model_matrix}{Markov\+::\+API\+::\+CUDA\+::\+CUDAModel\+Matrix}}
\begin{DoxyCompactList}\small\item\em Extension of \mbox{\hyperlink{class_markov_1_1_a_p_i_1_1_model_matrix}{Markov\+::\+API\+::\+Model\+Matrix}} which is modified to run on GPU devices. \end{DoxyCompactList}\end{DoxyCompactItemize}
\doxysubsection*{Namespaces}
\begin{DoxyCompactItemize}
\item 
 \mbox{\hyperlink{namespace_markov}{Markov}}
\begin{DoxyCompactList}\small\item\em Namespace for the markov-\/model related classes. Contains \mbox{\hyperlink{class_markov_1_1_model}{Model}}, \mbox{\hyperlink{class_markov_1_1_node}{Node}} and \mbox{\hyperlink{class_markov_1_1_edge}{Edge}} classes. \end{DoxyCompactList}\item 
 \mbox{\hyperlink{namespace_markov_1_1_a_p_i}{Markov\+::\+API}}
\begin{DoxyCompactList}\small\item\em Namespace for the \mbox{\hyperlink{class_markov_1_1_a_p_i_1_1_markov_passwords}{Markov\+Passwords}} \mbox{\hyperlink{namespace_markov_1_1_a_p_i}{API}}. \end{DoxyCompactList}\item 
 \mbox{\hyperlink{namespace_markov_1_1_a_p_i_1_1_c_u_d_a}{Markov\+::\+API\+::\+CUDA}}
\begin{DoxyCompactList}\small\item\em Namespace for objects requiring \mbox{\hyperlink{namespace_markov_1_1_a_p_i_1_1_c_u_d_a}{CUDA}} libraries. \end{DoxyCompactList}\end{DoxyCompactItemize}
\doxysubsection*{Functions}
\begin{DoxyCompactItemize}
\item 
\+\_\+\+\_\+global\+\_\+\+\_\+ void \mbox{\hyperlink{namespace_markov_1_1_a_p_i_1_1_c_u_d_a_a67e8dd9b192bc5a7f35b8187f376dccc}{Markov\+::\+API\+::\+CUDA\+::\+Fast\+Random\+Walk\+CUDAKernel}} (unsigned long int n, int min\+Len, int max\+Len, char $\ast$output\+Buffer, char $\ast$matrix\+Index, long int $\ast$total\+Edge\+Weights, long int $\ast$value\+Matrix, char $\ast$edge\+Matrix, int matrix\+Size, int memory\+Per\+Kernel\+Grid, unsigned long $\ast$seed)
\begin{DoxyCompactList}\small\item\em \mbox{\hyperlink{namespace_markov_1_1_a_p_i_1_1_c_u_d_a}{CUDA}} kernel for the Fast\+Random\+Walk operation. \end{DoxyCompactList}\item 
\+\_\+\+\_\+device\+\_\+\+\_\+ char $\ast$ \mbox{\hyperlink{namespace_markov_1_1_a_p_i_1_1_c_u_d_a_a6e4f16a152d93ed2aa9e854bf173de54}{Markov\+::\+API\+::\+CUDA\+::strchr}} (char $\ast$p, char c, int s\+\_\+len)
\begin{DoxyCompactList}\small\item\em srtchr implementation on {\bfseries{device}} space \end{DoxyCompactList}\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
CUDA accelerated extension of \mbox{\hyperlink{class_markov_1_1_a_p_i_1_1_model_matrix}{Markov\+::\+API\+::\+Model\+Matrix}}. 

\begin{DoxyAuthor}{Authors}
Ata Hakçıl
\end{DoxyAuthor}
Extension of \mbox{\hyperlink{class_markov_1_1_a_p_i_1_1_model_matrix}{Markov\+::\+API\+::\+Model\+Matrix}} which is modified to run on GPU devices. This implementation only supports Nvidia devices.

Class to flatten and reduce \mbox{\hyperlink{class_markov_1_1_model}{Markov\+::\+Model}} to a Matrix. Matrix level operations can be used for Generation events, with a significant performance optimization at the cost of O(\+N) memory complexity (O(1) memory space for slow mode)

To limit the maximum memory usage, each generation operation is partitioned into 50M chunks for allocation. Threads are sychronized and files are flushed every 50M operations. 

Definition in file \mbox{\hyperlink{cuda_model_matrix_8h_source}{cuda\+Model\+Matrix.\+h}}.


\label{index_md_Markopy_README}%
\Hypertarget{index_md_Markopy_README}%


\href{https://github.com/ignis-sec/Markopy/graphs/contributors}{\texttt{ }} \href{https://github.com/ignis-sec/Markopy/network/members}{\texttt{ }} \href{https://github.com/ignis-sec/Markopy/stargazers}{\texttt{ }} \href{https://github.com/ignis-sec/Markopy/issues}{\texttt{ }} 

~\newline
  \doxysubsubsection*{Markopy}

  Generate wordlists with markov models. ~\newline
 \href{https://markov.ignis.wtf}{\texttt{ HTML documentation}} · \href{https://markov.ignis.wtf/documentation.pdf}{\texttt{ PDF documentation}} · \href{https://github.com/ignis-sec/Markopy}{\texttt{ Github Page}} · \href{https://github.com/ignis-sec/Markopy/issues}{\texttt{ Report Bug}} · \href{https://github.com/ignis-sec/Markopy/pulls}{\texttt{ Add a Bug}}  

 \doxyparagraph*{Table of Contents}

 
\begin{DoxyEnumerate}
\item \href{\#about-the-project}{\texttt{ About The Project}} 
\begin{DoxyItemize}
\item \href{\#possible-use-cases}{\texttt{ Possible Use Cases}} 
\item \href{\#getting-started}{\texttt{ Getting Started}} 
\item \href{\#releases}{\texttt{ Releases}} 
\end{DoxyItemize}
\item \href{\#using}{\texttt{ Using the Project}} 
\begin{DoxyItemize}
\item \href{\#using-markopy}{\texttt{ Using Markopy/\+Cuda\+Markopy}} 
\begin{DoxyItemize}
\item \href{\#markopy-help}{\texttt{ Help}} 
\item \href{\#markopy-eval}{\texttt{ Evaluation}} 
\item \href{\#markopy-select}{\texttt{ Model Selection}} 
\item \href{\#markopy-train}{\texttt{ Training}} 
\item \href{\#markopy-generate}{\texttt{ Generation}} 
\end{DoxyItemize}
\end{DoxyItemize}
\item \href{\#building}{\texttt{ Building}} 
\begin{DoxyItemize}
\item \href{\#cmake-configuration}{\texttt{ CMake configuration}} 
\begin{DoxyItemize}
\item \href{\#build-all}{\texttt{ Build everything}} 
\item \href{\#build-libs}{\texttt{ Build libraries only}} 
\item \href{\#build-cuda-libs}{\texttt{ Build CUDA-\/accelerated libraries}} 
\item \href{\#build-py-libs}{\texttt{ Build python module \& libraries}} 
\item \href{\#build-cpy-libs}{\texttt{ Build CUDA accelerated python module}} 
\item \href{\#build-cpy-libs-and-gui}{\texttt{ Build CUDA accelerated python module and the GUI}} 
\end{DoxyItemize}
\item \href{\#prequisites}{\texttt{ Prequisites}} 
\begin{DoxyItemize}
\item \href{\#general-prequisites}{\texttt{ General Prequisites}} 
\begin{DoxyItemize}
\item \href{\#general-prequisites-linux}{\texttt{ Linux}} 
\item \href{\#general-prequisites-win}{\texttt{ Windows}} 
\end{DoxyItemize}
\item \href{\#preq-mm}{\texttt{ Markov\+Model}} 
\item \href{\#preq-ma}{\texttt{ Markov\+API}} 
\item \href{\#preq-mac}{\texttt{ Markov\+APICLI}} 
\item \href{\#preq-mpy}{\texttt{ Markopy}} 
\item \href{\#preq-cma}{\texttt{ Cuda\+Markov\+API}} 
\item \href{\#preq-cmpy}{\texttt{ Cuda\+Markopy}} 
\item \href{\#preq-mpgui}{\texttt{ Markov\+Passwords\+GUI}} 
\end{DoxyItemize}
\item \href{\#installing-deps}{\texttt{ Installing Dependencies}} 
\begin{DoxyItemize}
\item \href{\#installing-deps-win}{\texttt{ Windows}} 
\item \href{\#installing-deps-lin}{\texttt{ Linux}} 
\end{DoxyItemize}
\end{DoxyItemize}
\item \href{\#file-structure}{\texttt{ File Structure}} 
\begin{DoxyItemize}
\item \href{\#model-structure}{\texttt{ Model}} 
\item \href{\#corpus-structure}{\texttt{ Corpus}} 
\end{DoxyItemize}
\item \href{\#known-issues}{\texttt{ Known Common Issues}} 
\item \href{\#contributing}{\texttt{ Contributing}} 
\item \href{\#contact}{\texttt{ Contact}} 
\end{DoxyEnumerate}

\DoxyHorRuler{0}
\hypertarget{index_autotoc_md2}{}\doxysection{About The Project}\label{index_autotoc_md2}


This projects primary goal is to create a comfortable development environment for working with \mbox{\hyperlink{namespace_markov}{Markov}} Models, as well as creating an end product which can be used for generating password wordlists using \mbox{\hyperlink{namespace_markov}{Markov}} Models.

This project contains following sub-\/projects\+:


\begin{DoxyItemize}
\item Markov\+Model
\begin{DoxyItemize}
\item A versatile header-\/only template library for basic \mbox{\hyperlink{namespace_markov}{Markov}} Model structure.
\end{DoxyItemize}
\item Markov\+API
\begin{DoxyItemize}
\item A static/dynamic library built on Markov\+Model, specialized to generate single-\/word lines.
\end{DoxyItemize}
\item Markov\+APICLI
\begin{DoxyItemize}
\item A command line interface built on top of Markov\+API
\end{DoxyItemize}
\item Markopy
\begin{DoxyItemize}
\item A CPython extension wrapper for Markov\+API, along with its own command line interface.
\end{DoxyItemize}
\item Markov\+Passwords\+GUI
\begin{DoxyItemize}
\item A graphical user interface for Markov\+API
\end{DoxyItemize}
\item Cuda\+Markov\+API
\begin{DoxyItemize}
\item GPU-\/accelerated wrapper for Markov\+API
\end{DoxyItemize}
\item Cuda\+Markopy
\begin{DoxyItemize}
\item GPU-\/accelereted wrapper for Cuda\+Markov\+API
\end{DoxyItemize}
\end{DoxyItemize}\hypertarget{index_autotoc_md3}{}\doxysubsection{Possible Use Cases}\label{index_autotoc_md3}


While main focus of the development has been towards random walk performance and password generation, underlying libraries could be used for other applications such as specific use cases of hidden markov models in bioinformatics and gene research.\hypertarget{index_autotoc_md4}{}\doxysubsection{Getting Started}\label{index_autotoc_md4}


If you\textquotesingle{}d just like to use the project without contributing, check out the releases page. Latest minor release (0.\+8.\+x, 0.\+9.\+x) is even with main branch, and latest patch release (0.\+8.\+1, 0.\+8.\+2) is even with development branch.\hypertarget{index_autotoc_md5}{}\doxysubsection{Releases}\label{index_autotoc_md5}


Releases are maintained automatically via github actions. Each push to the main branch will trigger a minor version release, while each accepted pull request into the development branch will trigger a patch version release.

Pull requests to the development branch will also trigger a draft release only visible to the maintainers.

Release files contain\+:
\begin{DoxyItemize}
\item libmarkov-\/\{version\}-\/\{platform\}.zip
\begin{DoxyItemize}
\item Depending on the platform, contains the libmarkov.\+so or markov.\+lib from that version.
\end{DoxyItemize}
\item libcudamarkov-\/\{version\}-\/\{platform\}.zip
\begin{DoxyItemize}
\item Depending on the platform, contains the libcudamarkov.\+so or cudamarkov.\+lib from that version.
\end{DoxyItemize}
\item markopy-\/\{version\}-\/\{platform\}-\/py\{ver\}.\{extension\}.zip
\begin{DoxyItemize}
\item Depending on the paltform, contains markopy.\+so or markopy.\+pyd. CPython extensions are compiled for specific versions. If your python version is not supported by the releases, you can create an issue, or build it yourself using the python3.\+x-\/dev package.
\end{DoxyItemize}
\item cudamarkopy-\/\{version\}-\/\{platform\}-\/py\{ver\}.\{extension\}.zip
\begin{DoxyItemize}
\item Depending on the paltform, contains cudamarkopy.\+so or cudamarkopy.\+pyd. CPython extensions are compiled for specific versions. If your python version is not supported by the releases, you can create an issue, or build it yourself using the python3.\+x-\/dev package.
\end{DoxyItemize}
\item models-\/\{version\}.zip
\begin{DoxyItemize}
\item Contains the latest models with the release version. Contains base models (untrained), trained models, and language-\/specific models.
\end{DoxyItemize}
\end{DoxyItemize}

\DoxyHorRuler{0}
\hypertarget{index_autotoc_md7}{}\doxysection{Using the Project}\label{index_autotoc_md7}


You may use any section of this project, but we highly recommend using Markopy/\+Cuda\+Markopy python modules becaue they are optimized for the better user experience.

\href{https://asciinema.org/a/QeHkl7rZZnD8TiyZ4Gm1eZP6R}{\texttt{ }}\hypertarget{index_autotoc_md8}{}\doxysubsection{Using Markopy/\+Cuda\+Markopy}\label{index_autotoc_md8}


You can access basic operations from various model types using the python module, and if you are inexperienced with\+:
\begin{DoxyItemize}
\item Libmarkov and Libcudamarkov internals
\item C++ code in general
\item Importing and extending libraries in general
\item Working with Python/\+C++ intermixed code
\end{DoxyItemize}

We strongly recommend using the python module.

While almost all of the python files provide their own entry point, you should use \mbox{\hyperlink{markopy_8py}{markopy.\+py}} or \mbox{\hyperlink{cudamarkopy_8py}{cudamarkopy.\+py}} depending on your preferences. Please note that CUDA code will not run without an NVIDIA graphics card, and without CUDA runtime.

\mbox{\hyperlink{markopy_8py}{markopy.\+py}} and \mbox{\hyperlink{cudamarkopy_8py}{cudamarkopy.\+py}} will let you select the model type you want to use with the -\/mt parameter. With each model, there are slightly different parameters available.

For top level CLI selector (\mbox{\hyperlink{markopy_8py}{markopy.\+py}} and \mbox{\hyperlink{cudamarkopy_8py}{cudamarkopy.\+py}}) 
\begin{DoxyCode}{0}
\DoxyCodeLine{Model Mode selection choices:}
\DoxyCodeLine{usage: cudamarkopy.py [-\/mt MODEL\_TYPE] [-\/h] [-\/ev EVALUATE] [-\/evt EVALUATE\_TYPE]}
\DoxyCodeLine{}
\DoxyCodeLine{Python wrapper for MarkovPasswords.}
\DoxyCodeLine{}
\DoxyCodeLine{optional arguments:}
\DoxyCodeLine{  -\/mt MODEL\_TYPE, -\/-\/model\_type MODEL\_TYPE}
\DoxyCodeLine{                        Model type to use. Accepted values: MP, MMX}
\DoxyCodeLine{  -\/h, -\/-\/help            Model type to use. Accepted values: MP, MMX}
\DoxyCodeLine{  -\/ev EVALUATE, -\/-\/evaluate EVALUATE}
\DoxyCodeLine{                        Evaluate a models integrity}
\DoxyCodeLine{  -\/evt EVALUATE\_TYPE, -\/-\/evaluate\_type EVALUATE\_TYPE}
\DoxyCodeLine{                        Evaluation type, model or corpus}
\DoxyCodeLine{}
\DoxyCodeLine{        Sample runs:}
\DoxyCodeLine{        markopy.py -\/mt MP generate trained.mdl -\/n 500 -\/w output.txt}
\DoxyCodeLine{            Import trained.mdl, and generate 500 lines to output.txt}
\DoxyCodeLine{}
\DoxyCodeLine{        markopy.py -\/mt MMX generate trained.mdl -\/n 500 -\/w output.txt}
\DoxyCodeLine{            Import trained.mdl, and generate 500 lines to output.txt}
\DoxyCodeLine{        }
\DoxyCodeLine{        cudamarkopy.py -\/mt CUDA generate trained.mdl -\/n 500 -\/w output.txt}
\DoxyCodeLine{            Import trained.mdl, and generate 500 lines to output.txt}

\end{DoxyCode}
\hypertarget{index_autotoc_md9}{}\doxysubsubsection{Help}\label{index_autotoc_md9}


You can use the {\ttfamily -\/-\/help} function to print all the parameter details for all of the model types. Alternatively, you can combine it with {\ttfamily -\/mt} parameter to only print a single models parameters.\hypertarget{index_autotoc_md10}{}\doxysubsubsection{Evaluation}\label{index_autotoc_md10}


You can use the top level CLI selector to evaluate validity of a model or a corpus file (or many, if you provide a glob path pattern). A couple of examples\+:

\href{https://asciinema.org/a/tyEfEPVVoeAY96G5gpn12Xy4U}{\texttt{ }}

{\bfseries{Evaluate all of the models in the repository.}} 
\begin{DoxyCode}{0}
\DoxyCodeLine{python3 cudamarkopy.py -\/ev "{}../../../models/**/*"{} -\/evt model}

\end{DoxyCode}


Example outputs\+:


\begin{DoxyItemize}
\item A well trained model
\end{DoxyItemize}


\begin{DoxyCode}{0}
\DoxyCodeLine{[+] Model: trained.mdl: }
\DoxyCodeLine{[+] total edges: 9024}
\DoxyCodeLine{[+] unique left nodes: 95}
\DoxyCodeLine{[+] unique right nodes: 95}
\DoxyCodeLine{}
\DoxyCodeLine{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\# Checks \#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\# }
\DoxyCodeLine{[+] No dangling nodes             :✅ }
\DoxyCodeLine{[+] Median in expected ratio      :✅ }
\DoxyCodeLine{[+] Good bottom 10\%               :✅ }
\DoxyCodeLine{[+] 0 edges below threshold       :✅ }
\DoxyCodeLine{[+] Model structure               :✅ }
\DoxyCodeLine{[+] Model has any training        :✅ }
\DoxyCodeLine{[+] Model has training            :✅ }
\DoxyCodeLine{[+] Model training score: 3500088 :✅ }

\end{DoxyCode}

\begin{DoxyItemize}
\item An untrained model\+:
\end{DoxyItemize}


\begin{DoxyCode}{0}
\DoxyCodeLine{[+] Model: 2gram.mdl: }
\DoxyCodeLine{[+] total edges: 9024}
\DoxyCodeLine{[+] unique left nodes: 95}
\DoxyCodeLine{[+] unique right nodes: 95}
\DoxyCodeLine{division by zero}
\DoxyCodeLine{[+] 0 weighted edges are dangerous and may halt the model.}
\DoxyCodeLine{[+] Model seems to be untrained}
\DoxyCodeLine{[+] Model is not adequately trained. Might result in inadequate results}
\DoxyCodeLine{}
\DoxyCodeLine{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\# Checks \#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\# }
\DoxyCodeLine{[+] No dangling nodes             :✅ }
\DoxyCodeLine{[+] Exceptionn in check\_distrib   :❌ }
\DoxyCodeLine{[+] Median in expected ratio      :✅ }
\DoxyCodeLine{[+] Good bottom 10\%               :✅ }
\DoxyCodeLine{[+] Too many 0 edges              :❌ }
\DoxyCodeLine{[+] Model structure               :✅ }
\DoxyCodeLine{[+] Model has any training        :❌ }
\DoxyCodeLine{[+] Model has training            :❌ }
\DoxyCodeLine{[+] Model training score: 0.0     :❌ }

\end{DoxyCode}



\begin{DoxyItemize}
\item A model with inadequate training due to small corpus file 
\begin{DoxyCode}{0}
\DoxyCodeLine{[+] Model: corpus-\/Icelandic.mdl: }
\DoxyCodeLine{[+] total edges: 9024}
\DoxyCodeLine{[+] unique left nodes: 95}
\DoxyCodeLine{[+] unique right nodes: 95}
\DoxyCodeLine{[+] Model is not adequately trained. Might result in inadequate results}
\DoxyCodeLine{}
\DoxyCodeLine{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\# Checks \#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\# }
\DoxyCodeLine{[+] No dangling nodes             :✅ }
\DoxyCodeLine{[+] Median in expected ratio      :✅ }
\DoxyCodeLine{[+] Good bottom 10\%               :✅ }
\DoxyCodeLine{[+] 0 edges below threshold       :✅ }
\DoxyCodeLine{[+] Model structure               :✅ }
\DoxyCodeLine{[+] Model has any training        :✅ }
\DoxyCodeLine{[+] Model has training            :❌ }
\DoxyCodeLine{[+] Model training score: 208.68  :❌ }

\end{DoxyCode}

\item A model with improper training due to alphabet conflicts (Mostly seen in languages with non-\/latin alphabets)
\end{DoxyItemize}


\begin{DoxyCode}{0}
\DoxyCodeLine{[+] Model: corpus-\/Japanese.mdl: }
\DoxyCodeLine{[+] total edges: 9024}
\DoxyCodeLine{[+] unique left nodes: 95}
\DoxyCodeLine{[+] unique right nodes: 95}
\DoxyCodeLine{[+] Median is too left leaning and might indicate high entropy}
\DoxyCodeLine{}
\DoxyCodeLine{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\# Checks \#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\# }
\DoxyCodeLine{[+] No dangling nodes             :✅ }
\DoxyCodeLine{[+] Median too left leaning       :❌ }
\DoxyCodeLine{[+] Good bottom 10\%               :✅ }
\DoxyCodeLine{[+] 0 edges below threshold       :✅ }
\DoxyCodeLine{[+] Model structure               :✅ }
\DoxyCodeLine{[+] Model has any training        :✅ }
\DoxyCodeLine{[+] Model has training            :✅ }
\DoxyCodeLine{[+] Model training score: 10952   :✅ }

\end{DoxyCode}


{\bfseries{Evaluate a corpus file.}} 
\begin{DoxyCode}{0}
\DoxyCodeLine{python3 cudamarkopy.py -\/ev "{}../../../datasets/pwdb.corpus"{}}

\end{DoxyCode}



\begin{DoxyCode}{0}
\DoxyCodeLine{[+] Corpus: graduation.corpus: }
\DoxyCodeLine{[+] Delimiter is: b'\(\backslash\)t'}
\DoxyCodeLine{[+] Total number of lines: 157668136}
\DoxyCodeLine{[+] Sum of all string weights: 700089109}
\DoxyCodeLine{[+] Character total: 1498134485}
\DoxyCodeLine{[+] Average length: 9.501821503109545}
\DoxyCodeLine{[+] Average weight: 4.440270093635153}
\DoxyCodeLine{}
\DoxyCodeLine{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\# Checks \#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\# }
\DoxyCodeLine{[+] No structural conflicts       :✅ }

\end{DoxyCode}
\hypertarget{index_autotoc_md11}{}\doxysubsubsection{Model selection}\label{index_autotoc_md11}


You may use the -\/mt parameter from \mbox{\hyperlink{markopy_8py}{markopy.\+py}} or \mbox{\hyperlink{cudamarkopy_8py}{cudamarkopy.\+py}} to select a model type. Allowed parameters are\+: MP, MMX, CUDA

Following, is each of the parameters required for these model types.

{\bfseries{Following are applicable for -\/mt MP mode\+:}}


\begin{DoxyCode}{0}
\DoxyCodeLine{Python wrapper for MarkovPasswords.}
\DoxyCodeLine{}
\DoxyCodeLine{positional arguments:}
\DoxyCodeLine{  mode                  Process mode. Either 'Train', 'Generate', or 'Combine'.}
\DoxyCodeLine{  input                 Input model file. This model will be imported before starting operation.}
\DoxyCodeLine{}
\DoxyCodeLine{optional arguments:}
\DoxyCodeLine{  -\/h, -\/-\/help            show this help message and exit}
\DoxyCodeLine{  -\/o OUTPUT, -\/-\/output OUTPUT}
\DoxyCodeLine{                        Output model file. This model will be exported when done. Will be ignored for generation mode.}
\DoxyCodeLine{  -\/d DATASET, -\/-\/dataset DATASET}
\DoxyCodeLine{                        Dataset file to read input from for training. Will be ignored for generation mode.}
\DoxyCodeLine{  -\/s SEPERATOR, -\/-\/seperator SEPERATOR}
\DoxyCodeLine{                        Seperator character to use with training data.(character between occurrence and value)}
\DoxyCodeLine{  -\/t THREADS, -\/-\/threads THREADS}
\DoxyCodeLine{                        Number of lines to generate. Ignored in training mode.}
\DoxyCodeLine{  -\/v, -\/-\/verbosity       Output verbosity.}
\DoxyCodeLine{  -\/b, -\/-\/bulk            Bulk generate or bulk train every corpus/model in the folder.}
\DoxyCodeLine{  -\/w WORDLIST, -\/-\/wordlist WORDLIST}
\DoxyCodeLine{                        Wordlist file path to export generation results to. Will be ignored for training mode}
\DoxyCodeLine{  -\/-\/min MIN             Minimum length that is allowed during generation}
\DoxyCodeLine{  -\/-\/max MAX             Maximum length that is allowed during generation}
\DoxyCodeLine{  -\/n COUNT, -\/-\/count COUNT}
\DoxyCodeLine{                        Number of lines to generate. Ignored in training mode.}
\DoxyCodeLine{}
\DoxyCodeLine{Sample runs:}
\DoxyCodeLine{        base.py train untrained.mdl -\/d dataset.dat -\/s "{}\(\backslash\)t"{} -\/o trained.mdl}
\DoxyCodeLine{            Import untrained.mdl, train it with dataset.dat which has tab delimited data, output resulting model to trained.mdl}
\DoxyCodeLine{}
\DoxyCodeLine{        base.py generate trained.mdl -\/n 500 -\/w output.txt}
\DoxyCodeLine{            Import trained.mdl, and generate 500 lines to output.txt}
\DoxyCodeLine{}
\DoxyCodeLine{        base.py combine untrained.mdl -\/d dataset.dat -\/s "{}\(\backslash\)t"{} -\/n 500 -\/w output.txt}
\DoxyCodeLine{            Train and immediately generate 500 lines to output.txt. Do not export trained model.}
\DoxyCodeLine{}
\DoxyCodeLine{        base.py combine untrained.mdl -\/d dataset.dat -\/s "{}\(\backslash\)t"{} -\/n 500 -\/w output.txt -\/o trained.mdl}
\DoxyCodeLine{            Train and immediately generate 500 lines to output.txt. Export trained model.}
\DoxyCodeLine{}
\DoxyCodeLine{usage: cudamarkopy.py [-\/h] [-\/o OUTPUT] [-\/d DATASET] [-\/s SEPERATOR] [-\/t THREADS] [-\/v] [-\/b] [-\/w WORDLIST]}
\DoxyCodeLine{                      [-\/-\/min MIN] [-\/-\/max MAX] [-\/n COUNT]}
\DoxyCodeLine{                      mode input}

\end{DoxyCode}


{\bfseries{Following are applicable for -\/mt MMX mode\+:}}


\begin{DoxyCode}{0}
\DoxyCodeLine{usage: cudamarkopy.py [-\/h] [-\/t THREADS] [-\/v] [-\/b] [-\/w WORDLIST] [-\/-\/min MIN] [-\/-\/max MAX] [-\/n COUNT] [-\/st]}
\DoxyCodeLine{                      mode input}
\DoxyCodeLine{}
\DoxyCodeLine{Python wrapper for MarkovPasswords.}
\DoxyCodeLine{}
\DoxyCodeLine{positional arguments:}
\DoxyCodeLine{  mode                  Process mode. Either 'Train', 'Generate', or 'Combine'.}
\DoxyCodeLine{  input                 Input model file. This model will be imported before starting operation.}
\DoxyCodeLine{}
\DoxyCodeLine{optional arguments:}
\DoxyCodeLine{  -\/h, -\/-\/help            show this help message and exit}
\DoxyCodeLine{  -\/t THREADS, -\/-\/threads THREADS}
\DoxyCodeLine{                        Number of lines to generate. Ignored in training mode.}
\DoxyCodeLine{  -\/v, -\/-\/verbosity       Output verbosity.}
\DoxyCodeLine{  -\/b, -\/-\/bulk            Bulk generate or bulk train every corpus/model in the folder.}
\DoxyCodeLine{  -\/w WORDLIST, -\/-\/wordlist WORDLIST}
\DoxyCodeLine{                        Wordlist file path to export generation results to. Will be ignored for training mode}
\DoxyCodeLine{  -\/-\/min MIN             Minimum length that is allowed during generation}
\DoxyCodeLine{  -\/-\/max MAX             Maximum length that is allowed during generation}
\DoxyCodeLine{  -\/n COUNT, -\/-\/count COUNT}
\DoxyCodeLine{                        Number of lines to generate. Ignored in training mode.}
\DoxyCodeLine{  -\/st, -\/-\/stdout         Stdout mode}
\DoxyCodeLine{}
\DoxyCodeLine{Sample runs:}
\DoxyCodeLine{        base.py train untrained.mdl -\/d dataset.dat -\/s "{}\(\backslash\)t"{} -\/o trained.mdl}
\DoxyCodeLine{            Import untrained.mdl, train it with dataset.dat which has tab delimited data, output resulting model to trained.mdl}
\DoxyCodeLine{}
\DoxyCodeLine{        base.py generate trained.mdl -\/n 500 -\/w output.txt}
\DoxyCodeLine{            Import trained.mdl, and generate 500 lines to output.txt}
\DoxyCodeLine{}
\DoxyCodeLine{        base.py combine untrained.mdl -\/d dataset.dat -\/s "{}\(\backslash\)t"{} -\/n 500 -\/w output.txt}
\DoxyCodeLine{            Train and immediately generate 500 lines to output.txt. Do not export trained model.}
\DoxyCodeLine{}
\DoxyCodeLine{        base.py combine untrained.mdl -\/d dataset.dat -\/s "{}\(\backslash\)t"{} -\/n 500 -\/w output.txt -\/o trained.mdl}
\DoxyCodeLine{            Train and immediately generate 500 lines to output.txt. Export trained model.}

\end{DoxyCode}


{\bfseries{Following are applicable for -\/mt CUDA mode\+:}}


\begin{DoxyCode}{0}
\DoxyCodeLine{usage: cudamarkopy.py [-\/h] [-\/t THREADS] [-\/v] [-\/b] [-\/w WORDLIST] [-\/-\/min MIN] [-\/-\/max MAX] [-\/n COUNT] [-\/st] [-\/if]}
\DoxyCodeLine{                      mode input}
\DoxyCodeLine{}
\DoxyCodeLine{Python wrapper for MarkovPasswords.}
\DoxyCodeLine{}
\DoxyCodeLine{positional arguments:}
\DoxyCodeLine{  mode                  Process mode. Either 'Train', 'Generate', or 'Combine'.}
\DoxyCodeLine{  input                 Input model file. This model will be imported before starting operation.}
\DoxyCodeLine{}
\DoxyCodeLine{optional arguments:}
\DoxyCodeLine{  -\/h, -\/-\/help            show this help message and exit}
\DoxyCodeLine{  -\/t THREADS, -\/-\/threads THREADS}
\DoxyCodeLine{                        Number of lines to generate. Ignored in training mode.}
\DoxyCodeLine{  -\/v, -\/-\/verbosity       Output verbosity.}
\DoxyCodeLine{  -\/b, -\/-\/bulk            Bulk generate or bulk train every corpus/model in the folder.}
\DoxyCodeLine{  -\/w WORDLIST, -\/-\/wordlist WORDLIST}
\DoxyCodeLine{                        Wordlist file path to export generation results to. Will be ignored for training mode}
\DoxyCodeLine{  -\/-\/min MIN             Minimum length that is allowed during generation}
\DoxyCodeLine{  -\/-\/max MAX             Maximum length that is allowed during generation}
\DoxyCodeLine{  -\/n COUNT, -\/-\/count COUNT}
\DoxyCodeLine{                        Number of lines to generate. Ignored in training mode.}
\DoxyCodeLine{  -\/st, -\/-\/stdout         Stdout mode}
\DoxyCodeLine{  -\/if, -\/-\/infinite       Infinite generation mode}
\DoxyCodeLine{}
\DoxyCodeLine{Sample runs:}
\DoxyCodeLine{        base.py train untrained.mdl -\/d dataset.dat -\/s "{}\(\backslash\)t"{} -\/o trained.mdl}
\DoxyCodeLine{            Import untrained.mdl, train it with dataset.dat which has tab delimited data, output resulting model to trained.mdl}
\DoxyCodeLine{}
\DoxyCodeLine{        base.py generate trained.mdl -\/n 500 -\/w output.txt}
\DoxyCodeLine{            Import trained.mdl, and generate 500 lines to output.txt}
\DoxyCodeLine{}
\DoxyCodeLine{        base.py combine untrained.mdl -\/d dataset.dat -\/s "{}\(\backslash\)t"{} -\/n 500 -\/w output.txt}
\DoxyCodeLine{            Train and immediately generate 500 lines to output.txt. Do not export trained model.}
\DoxyCodeLine{}
\DoxyCodeLine{        base.py combine untrained.mdl -\/d dataset.dat -\/s "{}\(\backslash\)t"{} -\/n 500 -\/w output.txt -\/o trained.mdl}
\DoxyCodeLine{            Train and immediately generate 500 lines to output.txt. Export trained model.}

\end{DoxyCode}
\hypertarget{index_autotoc_md12}{}\doxysubsubsection{Training}\label{index_autotoc_md12}


If you do not have a custom corpus to train with, you may use one of the pre-\/trained models from the github releases.


\begin{DoxyCode}{0}
\DoxyCodeLine{python3 cudamarkopy.py train ../../../models/base-\/models/2gram.mdl -\/d ../../../datasets/graduation.corpus -\/s "{}\(\backslash\)\(\backslash\)t"{} -\/o test.mdl -\/vvvvvvvvv}

\end{DoxyCode}
\hypertarget{index_autotoc_md13}{}\doxysubsubsection{Generation}\label{index_autotoc_md13}


If you have not trained a model, you may download on of the trained models (preferably models/trained/trained.\+mdl) from the releases and use it for generation.

{\bfseries{Generating to a file}} 
\begin{DoxyCode}{0}
\DoxyCodeLine{python3 cudamarkopy.py generate trained.mdl -\/mt MMX -\/n 5000 -\/-\/min 6 -\/-\/max 12 -\/w test.txt -\/vvvv}

\end{DoxyCode}


{\bfseries{Generating to stdout}} 
\begin{DoxyCode}{0}
\DoxyCodeLine{python3 cudamarkopy.py generate trained.mdl -\/mt MMX -\/n 5000 -\/-\/min 6 -\/-\/max 12 -\/-\/stdout}

\end{DoxyCode}


{\bfseries{Generating with CUDA model}} {\bfseries{WARNING}} Do not use CUDA model unless you want to generate 500M+ lines. Prefer stdout mode with pipes instead of writing to disk whenever possible

{\bfseries{Using with Hashcat}} 
\begin{DoxyCode}{0}
\DoxyCodeLine{python3 cudamarkopy.py generate trained.mdl -\/mt CUDA -\/n 5000 -\/-\/min 6 -\/-\/max 12 -\/-\/stdout | hashcat -\/m 1400 hashes.txt -\/O}

\end{DoxyCode}


{\bfseries{Use with hashcat, continue until terminated}} 
\begin{DoxyCode}{0}
\DoxyCodeLine{python3 cudamarkopy.py generate trained.mdl -\/mt CUDA -\/n 5000 -\/-\/min 6 -\/-\/max 12 -\/-\/stdout -\/-\/infinite | hashcat -\/m 1400 hashes.txt -\/O}

\end{DoxyCode}


\DoxyHorRuler{0}
\hypertarget{index_autotoc_md15}{}\doxysection{Building}\label{index_autotoc_md15}
 You can build the project using cmake with g++ \& nvcc on linux, and msbuild \& nvcc on windows.\hypertarget{index_autotoc_md16}{}\doxysubsection{Prerequisites}\label{index_autotoc_md16}


You can find a list of the dependencies below. If you have any missing, check out the \href{\#setting-up-deps}{\texttt{ setting up prequisites}} part.\hypertarget{index_autotoc_md17}{}\doxysubsubsection{General prequisites}\label{index_autotoc_md17}


To build the simple core of this project, you\textquotesingle{}ll need\+: \hypertarget{index_autotoc_md18}{}\doxyparagraph{Linux}\label{index_autotoc_md18}



\begin{DoxyItemize}
\item CMake, preferably one of the latest versions.
\item CXX compiler, preferably g++ or clang++ (LLVM 3.\+9+).
\end{DoxyItemize}\hypertarget{index_autotoc_md19}{}\doxyparagraph{Windows}\label{index_autotoc_md19}

\begin{DoxyItemize}
\item CMake, preferably one of the latest versions.
\item CXX compiler, preferably msbuild(cl.\+exe) or clang++ (LLVM 3.\+9+). Please note that mingw is not recommended as it is not officially supported by the nvcc.\+exe, and might not be linkable if you are building the CUDA components too.
\end{DoxyItemize}\hypertarget{index_autotoc_md20}{}\doxysubsection{Markov\+Model}\label{index_autotoc_md20}
 This project does not have any extra dependencies, and it can be compiled with general dependencies without anything extra.\hypertarget{index_autotoc_md21}{}\doxysubsection{Markov\+API}\label{index_autotoc_md21}
 This project does not have any extra dependencies, and it can be compiled with general dependencies without anything extra.\hypertarget{index_autotoc_md22}{}\doxysubsection{Markov\+APICLI}\label{index_autotoc_md22}



\begin{DoxyItemize}
\item Boost.\+program\+\_\+options (tested on 1.\+71.\+0-\/1.\+76.\+0)
\end{DoxyItemize}\hypertarget{index_autotoc_md23}{}\doxysubsection{Markopy}\label{index_autotoc_md23}



\begin{DoxyItemize}
\item Boost.\+Python (tested on 1.\+71.\+0-\/1.\+76.\+0)
\item Python development package (tested on python 36-\/39)
\end{DoxyItemize}\hypertarget{index_autotoc_md24}{}\doxysubsection{Cuda\+Markov\+API}\label{index_autotoc_md24}



\begin{DoxyItemize}
\item CUDA toolkit (11.\+0+, c++17 support required)
\end{DoxyItemize}\hypertarget{index_autotoc_md25}{}\doxysubsection{Cuda\+Markopy}\label{index_autotoc_md25}



\begin{DoxyItemize}
\item CUDA toolkit (11.\+0+, c++17 support required)
\item Boost.\+Python (tested on 1.\+71.\+0-\/1.\+76.\+0)
\item Python development package (tested on python 36-\/39)
\end{DoxyItemize}\hypertarget{index_autotoc_md26}{}\doxysubsection{Markov\+Passwords\+GUI}\label{index_autotoc_md26}



\begin{DoxyItemize}
\item QT5 development environment. (qt5-\/qmake on ubuntu apt-\/get)
\item QTWeb\+Engine5 plugin. (qtwebengine5-\/dev on ubuntu apt-\/get)
\end{DoxyItemize}\hypertarget{index_autotoc_md27}{}\doxysubsection{CMake Configuration}\label{index_autotoc_md27}


You can build this project with cmake.

If you don\textquotesingle{}t have prequisites for some of the projects set up, you can use the partial set up configuration to ignore those projects when setting the project up.

If you do not meet the prequisites, you\textquotesingle{}ll have to partially set up the CMake file (you cant use --target to build some of the targets, because configuration phase will fail too).

Some examples for partially setting up and building the project are below.\hypertarget{index_autotoc_md28}{}\doxysubsubsection{Build everything}\label{index_autotoc_md28}



\begin{DoxyCode}{0}
\DoxyCodeLine{\$ cmake . -\/DPYTHON\_VER=38 \&\& cmake -\/-\/build .}

\end{DoxyCode}


This will build all the libraries and executables. Requires python-\/dev, CUDA, QT5, QT5-\/\+Webview\hypertarget{index_autotoc_md29}{}\doxysubsubsection{Build libraries only}\label{index_autotoc_md29}



\begin{DoxyCode}{0}
\DoxyCodeLine{\$ cmake . -\/DPARTIAL=1 -\/DB\_LIBS=1 \&\& cmake -\/-\/build .}

\end{DoxyCode}


Only build basic libraries. Requires only CXX compiler.\hypertarget{index_autotoc_md30}{}\doxysubsubsection{Build CUDA-\/accelerated libraries}\label{index_autotoc_md30}



\begin{DoxyCode}{0}
\DoxyCodeLine{\$ cmake . -\/DPARTIAL=1 -\/DB\_CUDA=1 \&\& cmake -\/-\/build .}

\end{DoxyCode}


Build libraries along with cuda accelerated ones.\hypertarget{index_autotoc_md31}{}\doxysubsubsection{Build python module \& libraries}\label{index_autotoc_md31}



\begin{DoxyCode}{0}
\DoxyCodeLine{\$ cmake . -\/DPARTIAL=1 -\/DPYTHON\_VER=39 \&\& cmake -\/-\/build .}

\end{DoxyCode}


Will build basic libraries and python modules.\hypertarget{index_autotoc_md32}{}\doxysubsubsection{Build CUDA accelerated python module}\label{index_autotoc_md32}



\begin{DoxyCode}{0}
\DoxyCodeLine{\$ cmake . -\/DPARTIAL=1 -\/DPYTHON\_VER=39 -\/DB\_CUDA=1 \&\& cmake -\/-\/build .}

\end{DoxyCode}


Will build cudamarkopy.\hypertarget{index_autotoc_md33}{}\doxysubsubsection{Build CUDA accelerated python module and the GUI}\label{index_autotoc_md33}



\begin{DoxyCode}{0}
\DoxyCodeLine{\$ cmake . -\/DPARTIAL=1 -\/DPYTHON\_VER=39 -\/DB\_CUDA=1 -\/DB\_GUI \&\& cmake -\/-\/build .}

\end{DoxyCode}


Combine methods

\DoxyHorRuler{0}
\hypertarget{index_autotoc_md35}{}\doxysubsection{Installing Dependencies}\label{index_autotoc_md35}
\hypertarget{index_autotoc_md36}{}\doxyparagraph{Windows}\label{index_autotoc_md36}



\begin{DoxyItemize}
\item QT\+: Install \href{https://doc.qt.io/qt-5/windows.html}{\texttt{ QT For Windows}}
\item Boost (program\+\_\+options and python)\+:
\begin{DoxyItemize}
\item Download Boost from \href{https://www.boost.org/users/download/}{\texttt{ its website}}. Prefer one of the tested versions, 1.\+71.\+0 to 1.\+76.\+0
\item Unzip the contents.
\item Launch \char`\"{}\+Visual Studio Developer Command Prompt\char`\"{} (If you don\textquotesingle{}t have this, properly set up the PATH\% variable for cl.\+exe)
\item Move to the boost installation directory. Bootstrap libraries with your python version\+: 
\begin{DoxyCode}{0}
\DoxyCodeLine{.\(\backslash\)bootstrap.bat -\/-\/with-\/python=\$(which python3.6) -\/-\/with-\/python-\/version=3.6;}

\end{DoxyCode}

\item Run {\ttfamily b2} to build the libraries. 
\begin{DoxyCode}{0}
\DoxyCodeLine{.\(\backslash\)b2.exe -\/-\/layout=system address-\/model=64 variant=release link=static runtime-\/link=shared threading=multi -\/-\/with-\/program\_options -\/-\/with-\/python stage;}

\end{DoxyCode}

\end{DoxyItemize}
\item Python\+: You can use the windows app store to download python runtime and libraries.
\end{DoxyItemize}\hypertarget{index_autotoc_md37}{}\doxyparagraph{Linux}\label{index_autotoc_md37}



\begin{DoxyItemize}
\item QT\+: Follow \href{https://wiki.qt.io/Install_Qt_5_on_Ubuntu}{\texttt{ this guide}} to install QT on Linux. Alternatively, on ubuntu you can {\ttfamily sudo apt-\/get install qt5-\/qmake qtwebengine5-\/dev}
\item Boost (program options and python)\+:
\begin{DoxyItemize}
\item Download Boost from \href{https://www.boost.org/users/download/}{\texttt{ its website}}. Prefer one of the tested versions, 1.\+71.\+0 to 1.\+76.\+0
\item Unzip the contents.
\item Move to the boost installation directory. Bootstrap libraries with your python version\+: 
\begin{DoxyCode}{0}
\DoxyCodeLine{./bootstrap.sh -\/-\/with-\/python=\$(which python3.6) -\/-\/with-\/python-\/version=3.6;}

\end{DoxyCode}

\item Run {\ttfamily b2} to build the libraries. 
\begin{DoxyCode}{0}
\DoxyCodeLine{./b2 variant=release link=static threading=multi -\/-\/with-\/program\_options install;}
\DoxyCodeLine{./b2 -\/-\/with-\/python -\/-\/buildid=3.6 install;}

\end{DoxyCode}

\end{DoxyItemize}
\item Boost (alternative)
\begin{DoxyItemize}
\item Use a package manager to install boost 
\begin{DoxyCode}{0}
\DoxyCodeLine{sudo apt-\/get install libboost-\/all-\/dev}

\end{DoxyCode}

\end{DoxyItemize}
\item Python\+: 
\begin{DoxyCode}{0}
\DoxyCodeLine{sudo apt-\/get install python3-\/dev}

\end{DoxyCode}

\end{DoxyItemize}

\DoxyHorRuler{0}
\hypertarget{index_autotoc_md39}{}\doxysection{File Structure}\label{index_autotoc_md39}


You may chose to create your own model structures or corpus files. Following, is the reference for the current structure for them.\hypertarget{index_autotoc_md40}{}\doxysubsection{Model}\label{index_autotoc_md40}


Model files are basically a list of edges in the model

Format is {\ttfamily \{left\+\_\+node\+\_\+content\},weight,\{right\+\_\+node\+\_\+content\}\textbackslash{}n}

Example\+:


\begin{DoxyCode}{0}
\DoxyCodeLine{l,5,r}
\DoxyCodeLine{l,12,g}
\DoxyCodeLine{...}

\end{DoxyCode}


There are additional requirements for a model for entry and termination nodes. Entry nodes are represented with 0x00, and termination nodes are represented with 0xff

It is expected (but not mandatory) to have an edge from starting node to all of the other nodes, and same applies for edges from each nodes to the termination nodes.

If termination node has any edges that it is position on the left (meaning model file expectation is to traverse to another node after termination node) it will be loaded to the edges, but will be ignored during the random walk logic.\hypertarget{index_autotoc_md41}{}\doxysubsection{Corpus}\label{index_autotoc_md41}


Corpus files are used to train models. You may chose to train your own model (preferably over an existing base model, like 2gram.\+mdl) to have your own generation style.

Corpus file format is\+:

{\ttfamily \{occurrence\}\{seperator\}\{string\}\textbackslash{}n}


\begin{DoxyItemize}
\item Occurrence is the weight associated with that string.
\item Seperator is a single character seperator used to seperate occurrence with the string
\item String is the password/string/sequence you want to add to the model.
\end{DoxyItemize}\hypertarget{index_autotoc_md42}{}\doxysection{Known Common issues}\label{index_autotoc_md42}
\hypertarget{index_autotoc_md43}{}\doxysubsection{Linux}\label{index_autotoc_md43}
\hypertarget{index_autotoc_md44}{}\doxysubsubsection{Markopy -\/ Python.\+h -\/ Not found}\label{index_autotoc_md44}
Make sure you have the development version of python package, which includes the required header files. Check if header files exist\+: {\ttfamily /usr/include/python$\ast$} or {\ttfamily locate Python.\+h}.

If it doesn\textquotesingle{}t, run {\ttfamily sudo apt-\/get install python3-\/dev}\hypertarget{index_autotoc_md45}{}\doxysubsubsection{Markopy/\+Markov\+API -\/ $\ast$.\+so not found, or other library related issues when building}\label{index_autotoc_md45}
Run\+: 
\begin{DoxyCode}{0}
\DoxyCodeLine{ls /usr/lib/x86\_64-\/linux-\/gnu/ | grep boost}

\end{DoxyCode}


and check the shared object filenames. A common issue is that lboost is required but filenames are formatted as libboost, or vice versa.

Do the same for python related library issues, run\+: 
\begin{DoxyCode}{0}
\DoxyCodeLine{ls /usr/lib/x86\_64-\/linux-\/gnu/ | grep python}

\end{DoxyCode}


to verify filename format is as required.

If not, you can modify the makefile, or create symlinks such as\+: 
\begin{DoxyCode}{0}
\DoxyCodeLine{ln -\/s /usr/lib/x86\_64-\/linux-\/gnu/libboost\_python38.so /usr/lib/x86\_64-\/linux-\/gnu/boost\_python38.so}

\end{DoxyCode}
\hypertarget{index_autotoc_md46}{}\doxysubsection{Windows}\label{index_autotoc_md46}
\hypertarget{index_autotoc_md47}{}\doxysubsubsection{Boost -\/ Bootstrap.\+bat \char`\"{}ctype.\+h\char`\"{} not found}\label{index_autotoc_md47}

\begin{DoxyItemize}
\item Make sure you are working in the \char`\"{}\+Visual Studio Developer Command Prompt\char`\"{} terminal.
\item Make sure you have Windows 10 SDK installed.
\item From VS developer terminal, run echo INCLUDE\%. If result does not have the windows sdk folders, run the following before running bootstrap (change your sdk version instead of 10.\+0.\+19041.\+0)\+: 
\begin{DoxyCode}{0}
\DoxyCodeLine{set INCLUDE=\%INCLUDE\%;C:\(\backslash\)Program Files (x86)\(\backslash\)Windows Kits\(\backslash\)NETFXSDK\(\backslash\)4.8\(\backslash\)include\(\backslash\)um;C:\(\backslash\)Program Files (x86)\(\backslash\)Windows Kits\(\backslash\)10\(\backslash\)include\(\backslash\)10.0.19041.0\(\backslash\)ucrt;C:\(\backslash\)Program Files (x86)\(\backslash\)Windows Kits\(\backslash\)10\(\backslash\)include\(\backslash\)10.0.19041.0\(\backslash\)shared;C:\(\backslash\)Program Files (x86)\(\backslash\)Windows Kits\(\backslash\)10\(\backslash\)include\(\backslash\)10.0.19041.0\(\backslash\)um;C:\(\backslash\)Program Files (x86)\(\backslash\)Windows Kits\(\backslash\)10\(\backslash\)include\(\backslash\)10.0.19041.0\(\backslash\)winrt;C:\(\backslash\)Program Files (x86)\(\backslash\)Windows Kits\(\backslash\)10\(\backslash\)include\(\backslash\)10.0.19041.0\(\backslash\)cppwinrt}
\DoxyCodeLine{}
\DoxyCodeLine{set LIB=\%LIB\%;C:\(\backslash\)Program Files (x86)\(\backslash\)Windows Kits\(\backslash\)10\(\backslash\)lib\(\backslash\)10.0.19041.0\(\backslash\)ucrt\(\backslash\)x64;C:\(\backslash\)Program Files (x86)\(\backslash\)Windows Kits\(\backslash\)10\(\backslash\)lib\(\backslash\)10.0.19041.0\(\backslash\)um\(\backslash\)x64}

\end{DoxyCode}

\end{DoxyItemize}\hypertarget{index_autotoc_md48}{}\doxysubsubsection{Cannot open file \char`\"{}$\ast$.\+lib\char`\"{}}\label{index_autotoc_md48}
Make sure you have set the BOOST\+\_\+\+ROOT environment variable correctly. Make sure you ran {\ttfamily b2} to build library files from boost sources.\hypertarget{index_autotoc_md49}{}\doxysubsubsection{Python.\+h not found}\label{index_autotoc_md49}
Make sure you have python installed, and make sure you set PYTHON\+\_\+\+PATH environment variable.

\DoxyHorRuler{0}
\hypertarget{index_autotoc_md51}{}\doxysection{Contributing}\label{index_autotoc_md51}


Feel free to contribute. We welcome all the issues and pull requests.\hypertarget{index_autotoc_md52}{}\doxysection{Contact}\label{index_autotoc_md52}


Twitter -\/ \href{https://twitter.com/ahakcil}{\texttt{ @ahakcil}} 